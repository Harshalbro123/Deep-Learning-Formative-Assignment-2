{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7q4pwd5S3xo"
      },
      "source": [
        "STEP 1 â€“ Install and Import Libraries\n",
        "\n",
        "ðŸ‘‰ Create a new cell and paste this, then run it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzp4ILnlS2m4"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3nxfsv_S-DT"
      },
      "source": [
        "Define Image Size and Simple Lane Model\n",
        "\n",
        "Weâ€™ll build a simple MobileNetV2 + upsampling model (MobileNetV3 can be version-dependent, so this is safer and still correct for your project)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VQ1YyUTzch-"
      },
      "outputs": [],
      "source": [
        "# 1) Define model (fixed upsampling)\n",
        "# -------------------\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "def build_lane_model():\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = False  # freeze backbone\n",
        "\n",
        "    inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "    # Normalization\n",
        "    x = layers.Rescaling(1./255)(inputs)\n",
        "\n",
        "    # Backbone (this will reduce 256x256 -> 8x8 feature map)\n",
        "    x = base_model(x)\n",
        "\n",
        "    # Simple SCNN-like block\n",
        "    def spatial_block(t):\n",
        "        h = layers.Conv2D(64, (1, 3), padding='same', activation='relu')(t)\n",
        "        v = layers.Conv2D(64, (3, 1), padding='same', activation='relu')(t)\n",
        "        return layers.Concatenate()([t, h, v])\n",
        "\n",
        "    x = spatial_block(x)\n",
        "\n",
        "    # Decoder: UpSample back to 256x256\n",
        "    # 8x8 -> 16x16\n",
        "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "    # 16x16 -> 32x32\n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "    # 32x32 -> 64x64\n",
        "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "    # 64x64 -> 128x128\n",
        "    x = layers.Conv2D(16, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "    # 128x128 -> 256x256\n",
        "    x = layers.Conv2D(8, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "    # Final 1-channel mask: 256x256x1\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_lane_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10MAEVxtTD-K"
      },
      "source": [
        "Make a Dummy â€œFakeâ€ Dataset (Just to Test Training)\n",
        "\n",
        "Right now you donâ€™t yet have lane images loaded, so weâ€™ll create dummy data.\n",
        "This is just to check that training runs and code is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0m6TUymzgwY"
      },
      "outputs": [],
      "source": [
        "# 2) Create dummy data with 256x256 masks\n",
        "# -------------------\n",
        "NUM_SAMPLES = 10\n",
        "\n",
        "X_dummy = np.random.randint(\n",
        "    0, 256, size=(NUM_SAMPLES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        ").astype('float32')\n",
        "\n",
        "Y_dummy = np.random.randint(\n",
        "    0, 2, size=(NUM_SAMPLES, IMG_HEIGHT, IMG_WIDTH, 1)\n",
        ").astype('float32')\n",
        "\n",
        "print(\"X_dummy shape:\", X_dummy.shape)\n",
        "print(\"Y_dummy shape:\", Y_dummy.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCvOabBVTXTz"
      },
      "source": [
        "Train the Model (Just a Quick Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McSmfoVI0hCD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3) Train for 2 epochs\n",
        "# -------------------\n",
        "print(\"\\nStarting training...\")\n",
        "history = model.fit(\n",
        "    X_dummy, Y_dummy,\n",
        "    epochs=2,\n",
        "    batch_size=2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nEpochs actually trained:\", len(history.history['loss']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnqK5Cy9Thzz"
      },
      "source": [
        "Test Prediction and Visualize (For Understanding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am9n8XQm0omV"
      },
      "outputs": [],
      "source": [
        "# Take one dummy image\n",
        "test_img = X_dummy[0:1]  # shape (1, H, W, 3)\n",
        "pred_mask = model.predict(test_img)[0, ..., 0]  # (H, W)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1); plt.title(\"Input image\"); plt.imshow(test_img[0].astype('uint8')); plt.axis(\"off\")\n",
        "plt.subplot(1,2,2); plt.title(\"Predicted mask\"); plt.imshow(pred_mask, cmap='gray'); plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu-rE_PeTlaF"
      },
      "source": [
        "making a folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hrUKmrAKSMd"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/my_lanes/images\n",
        "!mkdir -p /content/my_lanes/masks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_o-YwDSRSat"
      },
      "source": [
        "Replace the earlier X_dummy / Y_dummy with this loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBvwJcQBJjrR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "image_paths = sorted(glob.glob(\"/content/my_lanes/images/*\"))\n",
        "mask_paths  = sorted(glob.glob(\"/content/my_lanes/masks/*\"))\n",
        "\n",
        "print(\"Images:\", len(image_paths), \"Masks:\", len(mask_paths))\n",
        "\n",
        "X_real, Y_real = [], []\n",
        "\n",
        "for img_p, mask_p in zip(image_paths, mask_paths):\n",
        "    img = cv2.imread(img_p)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "    mask = cv2.imread(mask_p, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    mask = (mask > 128).astype(\"float32\")\n",
        "\n",
        "    X_real.append(img)\n",
        "    Y_real.append(mask[..., None])\n",
        "\n",
        "X_real = np.array(X_real, dtype=\"float32\")\n",
        "Y_real = np.array(Y_real, dtype=\"float32\")\n",
        "\n",
        "print(\"X_real shape:\", X_real.shape)\n",
        "print(\"Y_real shape:\", Y_real.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvPTA-sLRMqh"
      },
      "source": [
        "STEP 8 â€“ Train on Real Data\n",
        "\n",
        "Now train your existing model (no change needed):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1jX_YVsJ39Z"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_real, Y_real,\n",
        "    epochs=20,\n",
        "    batch_size=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W31zJ5vpRHfp"
      },
      "source": [
        "Take a input from folder for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 10 â€“ See Real Output\n",
        "\n",
        "Use the same visualization code as before:"
      ],
      "metadata": {
        "id": "bIjv05OETzfx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5d06d21"
      },
      "source": [
        "# Task\n",
        "Train the lane detection model using images and masks from '/content/my_lanes/images' and '/content/my_lanes/masks'. Then, create a new folder `/content/my_lanes/predict_input` for input images, load images from it, predict their corresponding lane masks, and save these predicted masks to `/content/my_lanes/predicted_masks`. Finally, visualize a few input images with their generated masks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20137883"
      },
      "source": [
        "# Task\n",
        "Train the lane detection model using images and masks from `/content/my_lanes/images` and `/content/my_lanes/masks`. Then, create a new folder `/content/my_lanes/predict_input` for input images, load images from it, predict their corresponding lane masks, and save these predicted masks to `/content/my_lanes/predicted_masks`. Finally, visualize a few input images with their generated masks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6896e1b8"
      },
      "source": [
        "## Create Input Prediction Folder\n",
        "\n",
        "### Subtask:\n",
        "Create a new directory named `/content/my_lanes/predict_input` where you will upload the images you want the model to predict on. You will need to manually upload images to this folder after it's created.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7ee0b52"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires creating a new directory named `/content/my_lanes/predict_input`. I will use the `!mkdir -p` shell command in a code cell to create this directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50603106"
      },
      "source": [
        "!mkdir -p /content/my_lanes/predict_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fd04e69"
      },
      "source": [
        "After the `/content/my_lanes/predict_input` directory has been created, please manually upload the images you wish to predict on into this folder. These images should be in a common format such as PNG or JPG. Once the images are uploaded, you can proceed with the next steps of the task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31d7c02c"
      },
      "source": [
        "After the `/content/my_lanes/predict_input` directory has been created, please manually upload the images you wish to predict on into this folder. These images should be in a common format such as PNG or JPG. Once the images are uploaded, you can proceed with the next steps of the task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f149cc0d"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires loading images from the newly created `/content/my_lanes/predict_input` directory, which is the first step towards predicting lane masks. This code block will also prepare for saving predicted masks by creating the output directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cb05474"
      },
      "source": [
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Create a directory for predicted masks\n",
        "!mkdir -p /content/my_lanes/predicted_masks\n",
        "\n",
        "# Define image dimensions (already defined, but good to ensure context)\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "# Get paths of input images for prediction\n",
        "predict_image_paths = sorted(glob.glob(\"/content/my_lanes/predict_input/*\"))\n",
        "\n",
        "print(f\"Found {len(predict_image_paths)} images for prediction.\")\n",
        "\n",
        "X_predict = []\n",
        "\n",
        "for img_p in predict_image_paths:\n",
        "    img = cv2.imread(img_p)\n",
        "    if img is None:\n",
        "        print(f\"Warning: Could not read image {img_p}. Skipping.\")\n",
        "        continue\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    X_predict.append(img)\n",
        "\n",
        "if not X_predict:\n",
        "    print(\"No images were loaded for prediction. Please upload images to /content/my_lanes/predict_input and run this cell again.\")\n",
        "    X_predict = np.array([], dtype=\"float32\").reshape(0, IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "else:\n",
        "    X_predict = np.array(X_predict, dtype=\"float32\")\n",
        "\n",
        "print(\"X_predict shape:\", X_predict.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff0b1df0"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the input images for prediction are loaded into `X_predict`, the next step is to use the trained `model` to predict the lane masks for these images. These predicted masks then need to be saved to the previously created `/content/my_lanes/predicted_masks` directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202d2ad9"
      },
      "source": [
        "print(\"Starting prediction...\")\n",
        "\n",
        "# Predict masks for the loaded images\n",
        "predicted_masks = model.predict(X_predict)\n",
        "\n",
        "print(\"Predicted masks shape:\", predicted_masks.shape)\n",
        "\n",
        "# Save the predicted masks\n",
        "for i, mask in enumerate(predicted_masks):\n",
        "    # Convert mask to 0-255 uint8 format\n",
        "    mask_img = (mask * 255).astype(np.uint8)\n",
        "\n",
        "    # Get original image filename to use for saving mask\n",
        "    original_filename = os.path.basename(predict_image_paths[i])\n",
        "    mask_filename = f\"predicted_mask_{original_filename}\"\n",
        "    save_path = os.path.join(\"/content/my_lanes/predicted_masks\", mask_filename)\n",
        "\n",
        "    cv2.imwrite(save_path, mask_img)\n",
        "\n",
        "print(f\"Saved {len(predicted_masks)} predicted masks to /content/my_lanes/predicted_masks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dfc1aba"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires adjusting the plot size and subplot arrangement to display input images and their corresponding predicted masks side-by-side, with each pair in a new row, for better visibility. I will modify the existing plotting code to implement these changes, including adjusting `num_to_visualize`, `figsize`, and the `plt.subplot()` calls as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbac1cba"
      },
      "source": [
        "num_to_visualize = 15 # Number of image-mask pairs to visualize. Changed for better visibility.\n",
        "\n",
        "plt.figure(figsize=(6, num_to_visualize * 3)) # Adjusted figsize for new layout\n",
        "\n",
        "for i in range(num_to_visualize):\n",
        "    # Display original image\n",
        "    plt.subplot(num_to_visualize, 2, 2*i + 1) # Arrange in num_to_visualize rows, 2 columns\n",
        "    plt.title(f\"Input Image {i+1}\")\n",
        "    plt.imshow(X_predict[i].astype('uint8'))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Display predicted mask\n",
        "    plt.subplot(num_to_visualize, 2, 2*i + 2) # Arrange in num_to_visualize rows, 2 columns\n",
        "    plt.title(f\"Predicted Mask {i+1}\")\n",
        "    plt.imshow(predicted_masks[i, ..., 0], cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}